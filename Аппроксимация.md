Аппроксимация — это процесс приближённого представления сложных математических объектов (функций, данных, фигур) с помощью более простых и удобных для анализа объектов.

### Виды аппроксимации:

1. **Аппроксимация функций** – приближённое представление одной функции другой, более простой (например, многочленом или тригонометрическим рядом).
2. **Аппроксимация данных** – нахождение зависимости, которая лучше всего описывает набор экспериментальных данных (например, метод наименьших квадратов).
3. **Аппроксимация геометрических объектов** – приближённое представление сложных фигур простыми (например, полигональная аппроксимация кривых).

Пример:  
Если у нас есть экспериментальные точки $(xi​,yi​)$, а мы подбираем линейную функцию $y=ax+b$, которая их описывает, – это и есть аппроксимация.

Часто аппроксимацию путают с интерполяцией. Главное отличие:

- **Интерполяция** точно проходит через все заданные точки.
- **Аппроксимация** лишь приближённо описывает их, допуская небольшие ошибки.
### Метод наименьших квадратов

Метод наименьших квадратов (МНК) — это статистический метод, используемый для аппроксимации данных и нахождения наиболее подходящей модели (например, линейной, полиномиальной и т. д.). Он стремится минимизировать сумму квадратов отклонений между наблюдаемыми значениями и значениями, предсказанными моделью.

```python
def linear_regression(X, y):
    # Количество наблюдений
    n = len(X)
    
    # Вычисляем средние значения для X и y
    mean_x = sum(X) / n
    mean_y = sum(y) / n
    
    # Инициализируем числитель и знаменатель для расчета наклона (β₂)
    numerator = 0
    denominator = 0
    
    # Вычисляем числитель и знаменатель
    for i in range(n):
        # Вычисляем отклонение от среднего для X и y
        deviation_x = X[i] - mean_x
        deviation_y = y[i] - mean_y
        
        # Обновляем числитель
        numerator += deviation_x * deviation_y
        
        # Обновляем знаменатель
        denominator += deviation_x ** 2
    
    # Наклон (β₂)
    beta_2 = numerator / denominator
    
    # Свободный член (β₁)
    beta_1 = mean_y - beta_2 * mean_x
    
    return beta_1, beta_2

# Пример использования
if __name__ == "__main__":
    # Пример данных
    X = [1, 2, 3, 4, 5]  # Наблюдаемые значения x
    y = [2, 3, 5, 7, 11]  # Соответствующие значения y

    # Находим коэффициенты
    coefficients = linear_regression(X, y)
    
    # Выводим коэффициенты
    print("Коэффициенты (β₁, β₂):", coefficients)
```

