Mean $\mu$ **(mu)** - среднее значение системы (из нескольких монет можем посчитать среднее)

Expected Value $\mathbb{E}$ - ожидаемое значение (при нескольких измерениях веса выводим среднее)

Variance или Дисперсия $σ^2$ или $Var(X)$ **(sigma squared)** - это среднее значение квадрата отклонения от среднего
$$Var(X)=E[(X−μ)^2]$$

Standard deviation или Стандартное отклонение $σ$ **(sigma)** или $s$ - квадратный корень из дисперсии 
$$σ=\sqrt{Var(X)}$$
	или такая запись
$$σ=\sqrt{\frac{1}{N} \sum_{n=1}^N \quad{(x_n - \mu)}^2} $$
Когда мы **оцениваем дисперсию по выборке (выборочной совокупности)**, а не по всей генеральной совокупности, мы делим не на $N$, а на $N−1$. Это называется **исправленная выборочная дисперсия**, и делается так для устранения смещения оценки. Может использоваться $s$ вместо $\mu$ :
$$s^2=\frac{1}{N-1} \sum_{n=1}^N \quad{(x_n - \mu)}^2$$
Коэффициент $N − 1$ называется поправкой Бесселя

**Normal Distribution Estimate** - нормальное распределение, также известное как Гауссово.
Кривая Гаусса так же называется PDF (Probability Density Function или Функция Плотности Вероятности) 
$$f(x;\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \ \quad e^{-\frac{1}{2}\left(\frac {x-\mu}{\sigma}\right)^2}$$

$f(x;\mu,\sigma^2)$ — это функция, которая описывает вероятность того, что случайная величина $X$ примет значение $x$. Это означает, что плотность вероятности $f(x)$ зависит от значений $\mu$ (среднего) и $\sigma^2$ (дисперсии).

При нормальном распределении работает правило трех сигм. Правило трех сигм выглядит следующим образом:
	**68%** значений лежат в пределах $\mu \pm 1\sigma$
	**95.44%** значений лежат в пределах $\mu \pm 2\sigma$
	**99.74%** значений лежат в пределах $\mu \pm 3\sigma$

Accuracy and Precision
- **Accuracy** → показывает, насколько измерение близко к **истинному значению**
- **Precision** → показывает, насколько **мало "шумит"** измерительный прибор

$\hat{x}_{n,n}$  - [[Оценка переменной во времени после наблюдений]] 

## Независимые случайные величины

Случайные величины бывают зависимыми и нет. Представьте, что вы бросаете иголку на плоскость и записываете координаты ее обоих концов. Эти две координаты зависимы, они связаны условием, что расстояние между ними всегда равно длине иголки, хотя и являются случайными величинами.  
Случайные величины независимы, если результат выпадения первой из них совершенно не зависит от результата выпадения второй из них. Если случайные величины независимы, то среднее значение их произведения равно произведению их средних значений:
$$\mathbb{E}[XY]=\mathbb{E}[X] \cdot \mathbb{E}[Y]$$
## State Update Equation (Уравнение Обновления Состояния)

Для обновления оценки среднего **не обязательно** хранить все измерения или их сумму (Обычный расчет среднего).  
Можно хранить только **предыдущее оценочное значение** и количество измерений:
$$\hat{x}_{n,n} = \hat{x}_{n-1,n} + \frac{1}{n} * (z_n - \hat{x}_{n-1,n})$$
Если схематично:
$$Оценка=Предыдущая \ оценка+Коэффициент⋅(Новое \ измерение−Предыдущая \ оценка)$$
$\frac{1}{n}$ - это **вес** или **обратный счётчик**, который делает новое измерение всё менее значимым при росте n

В фильтре Калмана вместо $\frac{1}{n}$​ используется **Kalman Gain** $K_n$​, который выбирается оптимально (на основе дисперсий).

Вместо $K_n$ пока что будет использоваться $\alpha_n$​:
​$$\hat{x}_{n,n} = \hat{x}_{n-1,n} + \alpha_n * (z_n - \hat{x}_{n-1,n})$$
$z_n - \hat{x}_{n-1,n}$ так же называется **Innovation** (инновация), так как содержит новую информацию

Первая оценка может быть приблизительной, основанной на каких-то других данных, это называется **Initial Guess** (Начальное предположение), а $\alpha_n$ будет равен единице $\alpha_n = 1$, в таком случае, подставив значения в формулу можно увидеть, что начальная оценка при коэффициенте 1 никак не повлияет на результат, так как сократится.


## State Extrapolation Equation (Уравнение Экстраполяции Состояния)

Еще называют Transition Equation (Уравнение перехода) или Prediction Equation (Уравнение прогнозирования)

Например ищем расстояние, которое пройдет объект, имеющий постоянную скорость при следующем измерении, то есть предсказываем его.

Скорость - это производная от пройденного пути:
$$\dot x = v = \frac{dx}{dt}$$
$$x_{n+1} = x_n + \Delta t \dot x_n$$
$$\dot{x}_{n+1} = \dot{x}_n$$
##  $\alpha - \beta$ фильтр или g-h фильтр

$\alpha - \beta$ фильтр - это **упрощённый аналог фильтра Калмана** для одномерных задач с постоянной скоростью.

Суть фильтра заключается в построении двух уравнений обновления состояния — для **измеряемого параметра** и **скорости изменения параметра** — чтобы дать оценку текущего значения и скорости изменения этого значения.

Затем, на основе этих оценок, производится **экстраполяция** (прогноз) состояния вперёд во времени.

Уравнение обновления состояния для измеряемого значения:
$$\hat{x}_{n,n} = \hat{x}_{n-1,n} + \alpha * (z_n - \hat{x}_{n-1,n})$$
Уравнение обновления состояния для скорости:
$$\hat{\dot{x}}_{n,n} = \hat{\dot{x}}_{n-1,n} + \beta * \left(\frac{z_n - \hat{x}_{n-1,n}}{\Delta t} \right)$$
Уравнение экстраполяции для измеряемого значения:
$$\hat{x}_{n+1,n} = \hat{x}_{n,n} + \Delta t * \hat{\dot{x}}_{n,n}$$
Уравнение экстраполяции скорости:
$$\hat{\dot{x}}_{n+1,n} = \hat{\dot{x}}_{n,n}$$
Коэффициенты $\alpha$ и $\beta$ определяют, насколько сильно фильтр доверяет новым измерениям по сравнению с предыдущими оценками:

- **Малые значения** $\alpha$ и $\beta$  → фильтр более сглаживает шум, но медленнее реагирует на резкие изменения (инерционность).
- **Большие значения** $\alpha$ и $\beta$  → фильтр быстрее реагирует на изменения, но становится чувствительнее к шуму.

Особенно важно: при слишком маленьком $\beta$ фильтр **будет медленно адаптироваться к изменениям скорости**, так как она почти не будет обновляться.

#### Когда **не стоит** использовать α-β фильтр:
- Когда изменения **резкие и нелинейные**
- Когда система имеет **ускорения, колебания, нестабильности** — тут лучше **α-β-γ** или Калман
- Когда есть **много измерений** или **сильно разный уровень шума**
##  $\alpha - \beta - \gamma$ фильтр или g-h-k фильтр 

$\alpha - \beta - \gamma$ фильтр - это **упрощённый аналог фильтра Калмана** для одномерных систем, в которых предполагается **равноускоренное движение**.

Полезно вспомнить классическую формулу равноускоренного движения:
$$s(t) = s_0 + v_0 t + \frac{at^2}{2}$$
Так как:
- Первая производная положения — это скорость ($\dot{x}$)
- Вторая производная — ускорение ($\ddot{x}$)

можно составить уравнения экстраполяции и обновления состояния.

#### Уравнения экстраполяции (прогноза):

- Положение:
$$\hat{x}_{n+1,n} = \hat{x}_{n,n} + \hat{\dot{x}}_{n,n} \Delta t + \hat{\ddot{x}}_{n,n} \frac{\Delta t^2}{2}$$
- Скорость:
$$\hat{\dot{x}}_{n+1,n} = \hat{\dot{x}}_{n,n} + \hat{\ddot{x}}_{n,n} \Delta t$$

- Ускорение:
$$\hat{\ddot{x}}_{n+1,n} = \hat{\ddot{x}}_{n,n}$$
#### Уравнения обновления (коррекции):

- Положение:
$$\hat{x}_{n,n} = \hat{x}_{n-1,n} + \alpha * (z_n - \hat{x}_{n-1,n})$$
- Скорость:
$$\hat{\dot{x}}_{n,n} = \hat{\dot{x}}_{n-1,n} + \beta * \left(\frac{z_n - \hat{x}_{n-1,n}}{\Delta t} \right)$$
- Ускорение:
$$\hat{\dot{x}}_{n,n} = \hat{\ddot{x}}_{n-1,n} + \gamma * \left(\frac{z_n - \hat{x}_{n-1,n}}{0.5\Delta t^2} \right)$$

#### Замечание:

Коэффициенты $\alpha, \beta, \gamma$ определяют степень доверия к измерениям. Меньшие значения — большее сглаживание, большие — быстрее реагируют на изменение.

#### Похожие фильтры и подходы:
Некоторые фильтры, основанные на схожих принципах оценки состояния:
- Wiener Filter 
- Bayes Filter 
- Fading-memory polynomial Filter 
- Expanding-memory (or growing-memory) polynomial Filter 
- Least-squares Filter 
- Benedict–Bordner Filter 
- Discounted least-squares α − β Filter 
- Critically damped α − β Filter 
- Growing-memory Filter 
- Kalman Filter 
- Extended Complex Kalman Filter 
- Gauss-Hermite Kalman Filter 
- Cubature Kalman Filter
- Particle Filter

## Одномерный фильтр Калмана без обработки процессного шума
### Covariance Extrapolation Equation (Уравнение ковариационной экстраполяции)

#### Экстраполяция дисперсии оценки для неменяющейся системы:

$$\hat{p}_{n+1,n} = \hat{p}_{n,n}$$
Где:
- $p$ - оценочная дисперсия

#### Экстраполяция дисперсии оценки для системы с постоянной скоростью:
$$p^x_{n+1,n} = p^x_{n,n} + \Delta t^2 \cdot p^v_{n,n}$$
$$p^v_{n+1,n} = p^v_{n,n}$$ Где:
- $p^x$ - дисперсия оценки положения
- $p^v$ - дисперсия оценки скорости

##### Объяснение формулы нахождения дисперсии оценки положения
Если у нас есть:
- $\text{Var}(x_n) = p^x$
- $\text{Var}(v_n) = p^v$

И мы вычисляем:
$$x_{n+1}​=x_n ​+ v_n​ \Delta t$$
То дисперсия $x_{n+1}$​, исходя из свойств дисперсий, будет:
$$Var(x_{n+1}​)=Var(x_n​ + v_n​ \Delta t) = p^x + \Delta t^2 * p^v$$
Потому что:

$x_n$​ и $v_n \cdot \Delta t$ — независимы
А дисперсия $aX + bY$ для независимых $X, Y$ — это $a^2 \text{Var}(X) + b^2 \text{Var}(Y)$. Данная формула выведена из формулы дисперсии линейной комбинации.

#### Что такое **ковариация**

**Ковариация** — это мера **совместной изменчивости двух случайных величин**.

- Если обе величины **растут вместе** → ковариация **положительная**
- Если одна растёт, а другая **убывает** → ковариация **отрицательная**
- Если вообще **никакой связи** → ковариация близка к **нулю**

##### Формула ковариации

Для двух величин X и Y:

$$\mathrm{Cov}(X, Y) = \mathbb{E}[(X - \mu_X)(Y - \mu_Y)]$$

- $\mu_X​, \mu_Y​$— их средние значения
- $\mathbb{E}$ — математическое ожидание (среднее)
##### Как это связано с дисперсией

**Дисперсия — это частный случай ковариации**.
	$\mathrm{Var}(X) = \mathrm{Cov}(X, X)$

То есть ковариация **самой с собой** — это и есть дисперсия.

### State Update (Обновление Состояния)

Текущая оценка состояния представляет собой средневзвешенное значение измерения и предыдущей оценки состояния:
$$\hat{x}_{n,n} = w_1  z_n + w_2 \hat{x}_{n,n-1}$$
$$w_1 + w_2 = 1$$
Можно записать так:
$$\hat{x}_{n,n} = w_1  z_n + (1 - w_1) \hat{x}_{n,n-1}$$
Соотношение между дисперсиями задается формулой:
$$p_{n,n} = w_1^2  r_n + (1 - w_1)^2 p_{n,n-1}$$
Где:
	$p_{n,n}$ - является дисперсией оптимальной комбинированной оценки
	$p_{n,n-1}$ - является дисперсией предыдущей оценки $\hat{x}_{n,n-1}$
	$r_n$ - дисперсия измерения $z_n$

**Если случайная величина $x$ распределена нормально** (то есть $x \sim \mathcal{N}(\mu, \sigma^2)$,  
**то при умножении её на константу $k$, распределение остаётся нормальным**,  
**а дисперсия умножается на $k^2$**.

#### Почему дисперсия умножается на $k^2$ 

Это следует из свойств дисперсии:
$$\mathrm{Var}(kX) = k^2 \cdot \mathrm{Var}(X)$$
— потому что дисперсия зависит от **квадрата расстояния от среднего**, а если данные растягиваются в k раз, расстояния тоже растягиваются в k раз → квадраты растягиваются в $k^2$ раз.

#### Поиск оптимальной оценки через минимизацию дисперсии

Когда мы ищем **оптимальную оценку** состояния (например, положения объекта), мы хотим, чтобы **дисперсия оценки** — то есть **неопределённость** $p_{n,n}$ — была как можно **меньше**.
Чтобы найти $w_1$, минимизирующее $p_{n,n}$, мы дифференцируем $p_{n,n}$ по $w_1$ и приравниваем результат к нулю.
$$\frac{dp_{n,n}}{d w_1}$$
Разложим:

$$\frac{d}{dw_1} \left( w_1^2 r_n + (1 - w_1)^2 p_{n,n-1} \right)$$
Считаем по частям:
1. Производная от $w_1^2 r_n$:

$$\frac{d}{dw_1} (w_1^2 r_n) = 2 w_1 r_n$$
2. Производная от $(1 - w_1)^2 p_{n,n-1}$:

Применяем цепное правило:
$$\frac{d}{dw_1} \left((1 - w_1)^2 p_{n,n-1}\right) = 2 (1 - w_1) (-1) \cdot p_{n,n-1} = -2 (1 - w_1) p_{n,n-1}$$
Складываем:

$$\frac{dp_{n,n}}{d w_1} = 2 w_1 r_n - 2 (1 - w_1) p_{n,n-1}$$

Приравниваем к нулю для минимума:

$$2 w_1 r_n - 2 (1 - w_1) p_{n,n-1} = 0$$
Решим уравнение:

Убираем двойки:
$$w_1 r_n = (1 - w_1) p_{n,n-1}$$​
Раскроем скобки:
$$w_1  r_n = p_{n,n-1} - w_1 p_{n,n-1}$$

Переносим всё с $w_1$ в одну сторону:
$$w_1 p_{n,n-1} + w_1  r_n = p_{n,n-1}$$
Выносим $w_1$:

$$w_1 (r_n + p_{n,n-1}) = p_{n,n-1}$$
И наконец:
$$w_1 = \frac{p_{n,n-1}}{p_{n,n-1} + r_n}$$
Подставим результат в оценку текущего состояния $\hat x_{n,n}$
$$\hat x_{n,n} = w_1 z_n + (1 − w_1) \hat x_{n,n−1} = w_1 z_n + \hat x_{n,n−1} −w_1 \hat x_{n,n−1} = \hat x_{n,n−1} + w_1 (z_n − \hat x_{n,n−1})$$
#### State Update Equation
$$\hat x_{n,n} = \hat x_{n,n−1} + \frac{p_{n,n-1}}{p_{n,n-1} + r_n} (z_n − \hat x_{n,n−1})$$

Вес значения, содержащего новые данные, называемое **Innovation** (инновационное) называется **Kalman Gain (Коэффициент Усиления Калмана)** и обозначается $K_n$

### Kalman Gain Equation (Уравнение Усиления Калмана)

$$K_n = \frac{Variance \ in \ Estimate}{Variance \ in \ Estimate + Variance \ in \ Meassurement}$$
$$K_n = \frac{p_{n,n-1}}{p_{n,n-1} + r_n}$$
Где:
- $p_{n,n-1}$ - экстраполированная оценочная дисперсия
- $r_n$ - дисперсия измерений

$K_n$ - число в диапазоне от 0 до 1
$$0 <= K_n <= 1$$
### Covariance update equation (Уравнение Обновления Ковариации)

Из выведенной ранее формулы соотношения между дисперсиями:
$$p_{n,n} = w_1^2  r_n + (1 - w_1)^2 p_{n,n-1}$$
Так как $w_1$ - это Kalman Gain, получаем:
$$p_{n,n} = K_n^2  r_n + (1 - K_n)^2 p_{n,n-1}$$
Выразим $(1 - K_n)$:
$$(1 - K_n) = \frac{r_n}{p_{n,n-1} + r_n}$$
Подставив  $K_n$ и $(1 - K_n)$ в уравнение соотношений дисперсий и решив его получим:
$$p_{n,n} = (1 - K_n) p_{n,n-1}$$

## Добавление шума процесса (process noise)

**Process noise $w_n$** - это неопределенность (uncertainty) математической модели динамической системы. Он отражает:

1. **Неточность модели** – реальная система может вести себя иначе, чем предсказывает модель.

2. **Внешние возмущения** – факторы, не учтённые в уравнениях (например, трение, ветер, шумы двигателя).

3. **Дискретизацию** – ошибки из-за перехода от непрерывного времени к дискретному.

Например при измерении температуры она колеблется в каком-то маленьком диапазоне.

**Process Noise Variance $q_n$** - дисперсия шума процесса

#### Экстраполяция дисперсии оценки для неменяющейся системы:

$$p_{n+1,n} = p_{n,n} + q_n$$
#### Экстраполяция дисперсии оценки для системы с постоянной скоростью:
$$p^x_{n+1,n} = p^x_{n,n} + \Delta t^2 \cdot p^v_{n,n}$$
$$p^v_{n+1,n} = p^v_{n,n} + q_n$$
## Многомерный фильтр Калмана

[[Ковариационная матрица]]

